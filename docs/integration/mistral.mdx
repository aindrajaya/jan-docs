---
sidebar_position: 7
---

# Jan Integration with Mistral AI

## Overview

This tutorial illustrates how to integrate with Mistral AI using Jan.

[Mistral AI](https://docs.mistral.ai/) provides two ways to use their Large Language Models (LLM): via their API or open-source models on Hugging Face. This tutorial demonstrates integrating Mistral AI with Jan using the API.

## Integrating Mistral AI with Jan

### Step 1: Confingure Mistral API Key

Find your API keys in the [Mistral API Key](https://console.mistral.ai/user/api-keys/) section, then input the Mistral AI API key into `~/jan/engines/openai.json`.

```json title="~/jan/engines/openai.json"
{
  "full_url": "https://api.mistral.ai/v1/chat/completions",
  "api_key": "<your-mistral-ai-api-key>"
}
```

### Step 2: Modify a Model JSON

1. Go to `~/jan/models`
2. make a folder named `mistral-(modelname)` (i.e., `mistral-tiny`). 
3. Create a `model.json` file with these settings:
    - Set `id` to the Mistral AI model ID.
    - Set `format` to `api`.
    - Set `engine` to `openai`.
    - Set `state` to `ready`.

```json title="~/jan/models/mistral-tiny/model.json"
{
  "sources": [
    {
      "filename": "mistral-tiny",
      "url": "https://mistral.ai/"
    }
  ],
  "id": "mistral-tiny",
  "object": "model",
  "name": "Mistral-7B-v0.2 (Tiny Endpoint)",
  "version": "1.0",
  "description": "Currently powered by Mistral-7B-v0.2, a better fine-tuning of the initial Mistral-7B released, inspired by the fantastic work of the community.",
  "format": "api",
  "settings": {},
  "parameters": {},
  "metadata": {
    "author": "Mistral AI",
    "tags": ["General", "Big Context Length"]
  },
  "engine": "openai"
}
```

:::note

Mistral AI provides different endpoints. Please check out their [endpoint documentation](https://docs.mistral.ai/platform/endpoints/) to find the one that suits your needs. In this example, we will use the `mistral-tiny` model.

:::

### Step 3: Start the Model

Restart Jan and go to the Hub. Find your model and select the Use button.